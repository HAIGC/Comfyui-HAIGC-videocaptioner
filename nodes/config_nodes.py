"""
é…ç½®èŠ‚ç‚¹
ç”¨äºé…ç½®è½¬å½•ã€LLMã€ç¿»è¯‘ç­‰å‚æ•°
"""

import os
import sys
from pathlib import Path
from typing import Tuple, Dict, Any

# è®¾ç½®è·¯å¾„å¹¶å¯¼å…¥
current_dir = Path(__file__).parent.parent
videocaptioner_path = current_dir / "VideoCaptioner"
if str(videocaptioner_path) not in sys.path:
    sys.path.insert(0, str(videocaptioner_path))

# å¯¼å…¥åŸºç¡€æ¨¡å—
try:
    from app.core.entities import (
        TranscribeConfig,
        TranscribeModelEnum,
        FasterWhisperModelEnum,
        VadMethodEnum,
    )
    
    DEPENDENCIES_OK = True
    print("[VideoCaptioner] ConfigNodes dependencies loaded successfully")
except Exception as e:
    print(f"[VideoCaptioner] ConfigNodes import error: {e}")
    import traceback
    traceback.print_exc()
    DEPENDENCIES_OK = False
    TranscribeConfig = None
    TranscribeModelEnum = None
    FasterWhisperModelEnum = None
    VadMethodEnum = None

# è·å– ComfyUI çš„ models ç›®å½•
def get_comfyui_models_dir():
    """è·å– ComfyUI æ ‡å‡† models ç›®å½•"""
    comfyui_root = Path(__file__).parent.parent.parent.parent
    models_dir = comfyui_root / "models" / "whisper"
    models_dir.mkdir(parents=True, exist_ok=True)
    return str(models_dir)


class TranscribeConfigNode:
    """
    è½¬å½•é…ç½®èŠ‚ç‚¹
    é…ç½®è¯­éŸ³è¯†åˆ«çš„è¯¦ç»†å‚æ•°
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "è½¬å½•æ¨¡å‹": ([
                    "Whisper",
                    "Jæ¥å£",
                    "Bæ¥å£",
                ], {
                    "default": "Whisper"
                }),
                "è¯­è¨€": ([
                    "auto", "zh", "en", "ja", "ko", "fr", "de", "es", "ru",
                ], {
                    "default": "zh"
                }),
                "æ¨¡å‹å¤§å°": ([
                    "belle-large-v3-zh-punct"
                ], {
                    "default": "belle-large-v3-zh-punct"
                }),
                "ä½¿ç”¨ç¼“å­˜": ("BOOLEAN", {"default": True}),
                "è¯çº§æ—¶é—´æˆ³": ("BOOLEAN", {"default": False}),
                "è¯­éŸ³æ£€æµ‹è¿‡æ»¤": ("BOOLEAN", {"default": False}),
                "è¯­éŸ³æ£€æµ‹é˜ˆå€¼": ("FLOAT", {
                    "default": 0.3,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.05,
                }),
                "æç¤ºæ¨¡å¼": ([
                    "è‡ªåŠ¨ä¼˜åŒ– ğŸ¯",
                    "ä¸­è‹±æ··åˆ ğŸŒ", 
                    "çº¯ä¸­æ–‡ ğŸ‡¨ğŸ‡³",
                    "çº¯è‹±æ–‡ ğŸ‡ºğŸ‡¸",
                    "å…³é—­ âŒ"
                ], {
                    "default": "å…³é—­ âŒ"
                }),
            },
            "optional": {
                "è®¾å¤‡": (["cpu", "cuda"], {"default": "cpu"}),  # é»˜è®¤ CPU é¿å…éœ€è¦ faster-whisper-xxl
                "è¯­éŸ³æ£€æµ‹æ–¹æ³•": ([
                    "silero_v4_fw",
                    "silero_v3",
                    "pyannote_v3",
                ], {
                    "default": "silero_v4_fw"
                }),
            }
        }
    
    RETURN_TYPES = ("TRANSCRIBE_CONFIG",)
    RETURN_NAMES = ("è½¬å½•é…ç½®",)
    FUNCTION = "create_config"
    CATEGORY = "video/subtitle/config"
    
    def create_config(
        self,
        è½¬å½•æ¨¡å‹: str,
        è¯­è¨€: str,
        æ¨¡å‹å¤§å°: str,
        ä½¿ç”¨ç¼“å­˜: bool,
        è¯çº§æ—¶é—´æˆ³: bool,
        è¯­éŸ³æ£€æµ‹è¿‡æ»¤: bool,
        è¯­éŸ³æ£€æµ‹é˜ˆå€¼: float,
        æç¤ºæ¨¡å¼: str,
        è®¾å¤‡: str = "cpu",  # é»˜è®¤ CPU
        è¯­éŸ³æ£€æµ‹æ–¹æ³•: str = "silero_v4_fw",
        **kwargs,
    ) -> Tuple[Dict[str, Any]]:
        """
        åˆ›å»ºè½¬å½•é…ç½®
        
        Returns:
            (transcribe_config,): è½¬å½•é…ç½®å­—å…¸
        """
        # æ£€æŸ¥ä¾èµ–æ˜¯å¦åŠ è½½æˆåŠŸ
        if not DEPENDENCIES_OK or TranscribeModelEnum is None:
            error_msg = "ä¾èµ–åŠ è½½å¤±è´¥ï¼è¯·æ£€æŸ¥ VideoCaptioner å®‰è£…æ˜¯å¦å®Œæ•´"
            print(f"[VideoCaptioner] {error_msg}")
            return ({"error": error_msg},)
        
        # æ˜ å°„æ¨¡å‹åç§°
        model_mapping = {
            "Whisper": TranscribeModelEnum.FASTER_WHISPER,
            "Jæ¥å£": TranscribeModelEnum.JIANYING,
            "Bæ¥å£": TranscribeModelEnum.BIJIAN,
        }
        
        # Whisper åŸç‰ˆæ¨¡å‹æ˜ å°„
        from app.core.entities import WhisperModelEnum
        whisper_model_mapping = {
            "tiny": WhisperModelEnum.TINY,
            "base": WhisperModelEnum.BASE,
            "small": WhisperModelEnum.SMALL,
            "medium": WhisperModelEnum.MEDIUM,
            "turbo": WhisperModelEnum.TURBO,
            "large-v2": WhisperModelEnum.LARGE_V2,
            "large-v3": WhisperModelEnum.LARGE_V3,
        }
        
        # FasterWhisper æ¨¡å‹æ˜ å°„
        faster_whisper_model_mapping = {
            "tiny": FasterWhisperModelEnum.TINY,
            "base": FasterWhisperModelEnum.BASE,
            "small": FasterWhisperModelEnum.SMALL,
            "medium": FasterWhisperModelEnum.MEDIUM,
            "turbo": FasterWhisperModelEnum.LARGE_V3_TURBO,
            "large-v2": FasterWhisperModelEnum.LARGE_V2,
            "large-v3": FasterWhisperModelEnum.LARGE_V3,
            "belle-large-v3-zh-punct": FasterWhisperModelEnum.BELLE_LARGE_V3_ZH_PUNCT,
        }
        
        vad_method_mapping = {
            "silero_v4_fw": VadMethodEnum.SILERO_V4_FW,
            "silero_v3": VadMethodEnum.SILERO_V3,
            "pyannote_v3": VadMethodEnum.PYANNOTE_V3,
        }
        
        # è·å– ComfyUI models ç›®å½•
        models_dir = get_comfyui_models_dir()
        
        # åˆ›å»ºé…ç½®å¯¹è±¡
        config = TranscribeConfig(
            transcribe_model=model_mapping.get(è½¬å½•æ¨¡å‹),
            transcribe_language=è¯­è¨€,
            whisper_model=whisper_model_mapping.get(æ¨¡å‹å¤§å°),
            faster_whisper_model=faster_whisper_model_mapping.get(æ¨¡å‹å¤§å°),
            use_asr_cache=ä½¿ç”¨ç¼“å­˜,
            need_word_time_stamp=è¯çº§æ—¶é—´æˆ³,
            faster_whisper_device=è®¾å¤‡,
            faster_whisper_model_dir=models_dir,  # å¤ç”¨ç»Ÿä¸€æ¨¡å‹ç›®å½•
            faster_whisper_vad_filter=è¯­éŸ³æ£€æµ‹è¿‡æ»¤,
            faster_whisper_vad_threshold=è¯­éŸ³æ£€æµ‹é˜ˆå€¼,
            faster_whisper_vad_method=vad_method_mapping.get(è¯­éŸ³æ£€æµ‹æ–¹æ³•),
            faster_whisper_prompt=None,
        )
        
        # ç”Ÿæˆ initial_promptï¼ˆæç¤ºè¯ï¼‰
        initial_prompt = self._generate_prompt(æç¤ºæ¨¡å¼, è¯­è¨€)
        
        # å°†æç¤ºè¯ä¿å­˜åˆ°é…ç½®å¯¹è±¡ï¼Œä¾¿äºé€šç”¨è½¬å½•è·¯å¾„ä½¿ç”¨
        try:
            setattr(config, "faster_whisper_prompt", initial_prompt or None)
        except Exception:
            pass
        
        # è½¬æ¢ä¸ºå­—å…¸ä»¥ä¾¿ä¼ é€’
        config_dict = {
            "config_object": config,
            "transcribe_model": è½¬å½•æ¨¡å‹,
            "language": è¯­è¨€,
            "whisper_model": æ¨¡å‹å¤§å°,
            "prompt_mode": æç¤ºæ¨¡å¼,
            "initial_prompt": initial_prompt,
        }
        
        print(f"[TranscribeConfig] è¯†åˆ«æç¤ºæ¨¡å¼: {æç¤ºæ¨¡å¼}")
        if initial_prompt:
            print(f"[TranscribeConfig] æç¤ºè¯: {initial_prompt[:100]}...")
        
        return (config_dict,)
    
    def _generate_prompt(self, prompt_mode: str, language: str) -> str:
        """
        æ ¹æ®æç¤ºæ¨¡å¼ç”Ÿæˆ initial_prompt
        
        initial_prompt æ˜¯ Whisper çš„ä¸€ä¸ªé‡è¦å‚æ•°ï¼Œå¯ä»¥ï¼š
        1. æç¤ºæ¨¡å‹ä¿ç•™ä¸“æœ‰åè¯ï¼ˆå¦‚ ComfyUI, OpenAI ç­‰ï¼‰
        2. æŒ‡å®šè¾“å‡ºæ ¼å¼å’Œé£æ ¼
        3. æé«˜è¯†åˆ«å‡†ç¡®ç‡
        
        Args:
            prompt_mode: æç¤ºæ¨¡å¼
            language: è¯­è¨€ä»£ç 
            
        Returns:
            initial_prompt å­—ç¬¦ä¸²
        """
        if "å…³é—­" in prompt_mode:
            return ""
        
        if "è‡ªåŠ¨ä¼˜åŒ–" in prompt_mode:
            # æ ¹æ®è¯­è¨€è‡ªåŠ¨é€‰æ‹©
            if language == "zh":
                return "ä»¥ä¸‹æ˜¯æ™®é€šè¯çš„å¥å­ï¼Œè¯·ä¿ç•™è‹±æ–‡ä¸“æœ‰åè¯åŸæ–‡ï¼Œå¦‚ ComfyUI, Stable Diffusion, Python, AI, GPU, CPU, API ç­‰æŠ€æœ¯æœ¯è¯­ã€‚"
            elif language == "en":
                return "The following is a transcript in English. Preserve proper nouns and technical terms."
            elif language == "auto":
                return "ä»¥ä¸‹æ˜¯ä¸­è‹±æ–‡æ··åˆå†…å®¹ã€‚å¯¹äºä¸­æ–‡éƒ¨åˆ†ä½¿ç”¨ç®€ä½“ä¸­æ–‡ï¼Œå¯¹äºè‹±æ–‡ä¸“æœ‰åè¯å’ŒæŠ€æœ¯æœ¯è¯­ä¿ç•™åŸæ–‡ï¼Œå¦‚ ComfyUI, API, GPU, Python, Stable Diffusion, OpenAI, ChatGPT ç­‰ã€‚"
            else:
                return ""
        
        if "ä¸­è‹±æ··åˆ" in prompt_mode:
            return "ä»¥ä¸‹æ˜¯ä¸­è‹±æ–‡æ··åˆå†…å®¹ã€‚å¯¹äºä¸­æ–‡éƒ¨åˆ†ä½¿ç”¨ç®€ä½“ä¸­æ–‡ï¼Œå¯¹äºè‹±æ–‡ä¸“æœ‰åè¯å’ŒæŠ€æœ¯æœ¯è¯­ä¿ç•™åŸæ–‡ï¼Œå¦‚ ComfyUI, API, GPU, Python, Stable Diffusion, OpenAI, ChatGPT, CUDA, PyTorch, TensorFlow, Node, Workflow ç­‰ã€‚ä¸è¦å°†è‹±æ–‡ç¿»è¯‘æˆä¸­æ–‡åŒéŸ³å­—ã€‚"
        
        if "çº¯ä¸­æ–‡" in prompt_mode:
            return "ä»¥ä¸‹æ˜¯æ™®é€šè¯çš„å¥å­ã€‚"
        
        if "çº¯è‹±æ–‡" in prompt_mode:
            return "The following is a transcript in English."
        
        return ""


class LLMConfigNode:
    """
    LLM é…ç½®èŠ‚ç‚¹
    é…ç½®å¤§è¯­è¨€æ¨¡å‹çš„å‚æ•°
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "æ¨¡å‹": ("STRING", {
                    "default": "gpt-4o-mini",
                }),
                "APIåœ°å€": ("STRING", {
                    "default": os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1"),
                }),
                "APIå¯†é’¥": ("STRING", {
                    "default": os.getenv("OPENAI_API_KEY", ""),
                }),
                "æ¸©åº¦": ("FLOAT", {
                    "default": 0.7,
                    "min": 0.0,
                    "max": 2.0,
                    "step": 0.1,
                }),
                "çº¿ç¨‹æ•°": ("INT", {
                    "default": 5,
                    "min": 1,
                    "max": 20,
                    "step": 1,
                }),
            },
        }
    
    RETURN_TYPES = ("LLM_CONFIG",)
    RETURN_NAMES = ("LLMé…ç½®",)
    FUNCTION = "create_config"
    CATEGORY = "video/subtitle/config"
    
    def create_config(
        self,
        æ¨¡å‹: str,
        APIåœ°å€: str,
        APIå¯†é’¥: str,
        æ¸©åº¦: float,
        çº¿ç¨‹æ•°: int,
    ) -> Tuple[Dict[str, Any]]:
        """
        åˆ›å»º LLM é…ç½®
        
        Returns:
            (llm_config,): LLM é…ç½®å­—å…¸
        """
        # è®¾ç½®ç¯å¢ƒå˜é‡
        if APIåœ°å€:
            os.environ["OPENAI_BASE_URL"] = APIåœ°å€
        if APIå¯†é’¥:
            os.environ["OPENAI_API_KEY"] = APIå¯†é’¥
        
        config = {
            "model": æ¨¡å‹,
            "base_url": APIåœ°å€,
            "api_key": APIå¯†é’¥,
            "temperature": æ¸©åº¦,
            "thread_num": çº¿ç¨‹æ•°,
        }
        
        return (config,)


class TranslateConfigNode:
    """
    ç¿»è¯‘é…ç½®èŠ‚ç‚¹
    é…ç½®ç¿»è¯‘ç›¸å…³å‚æ•°
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "ç¿»è¯‘å™¨ç±»å‹": ([
                    "LLM å¤§æ¨¡å‹ç¿»è¯‘",
                    "DeepLx ç¿»è¯‘",
                    "å¾®è½¯ç¿»è¯‘",
                    "è°·æ­Œç¿»è¯‘",
                ], {
                    "default": "LLM å¤§æ¨¡å‹ç¿»è¯‘"
                }),
                "ç›®æ ‡è¯­è¨€": ([
                    "ç®€ä½“ä¸­æ–‡", "ç¹ä½“ä¸­æ–‡", "è‹±è¯­", "æ—¥æœ¬èª", "éŸ©è¯­",
                ], {
                    "default": "ç®€ä½“ä¸­æ–‡"
                }),
                "çº¿ç¨‹æ•°": ("INT", {
                    "default": 5,
                    "min": 1,
                    "max": 20,
                    "step": 1,
                }),
                "æ‰¹å¤„ç†æ•°é‡": ("INT", {
                    "default": 10,
                    "min": 1,
                    "max": 50,
                    "step": 1,
                }),
                "åæ€ç¿»è¯‘": ("BOOLEAN", {"default": False}),
            },
            "optional": {
                "LLMé…ç½®": ("LLM_CONFIG",),
            }
        }
    
    RETURN_TYPES = ("TRANSLATE_CONFIG",)
    RETURN_NAMES = ("ç¿»è¯‘é…ç½®",)
    FUNCTION = "create_config"
    CATEGORY = "video/subtitle/config"
    
    def create_config(
        self,
        ç¿»è¯‘å™¨ç±»å‹: str,
        ç›®æ ‡è¯­è¨€: str,
        çº¿ç¨‹æ•°: int,
        æ‰¹å¤„ç†æ•°é‡: int,
        åæ€ç¿»è¯‘: bool,
        LLMé…ç½®: Dict[str, Any] = None,
    ) -> Tuple[Dict[str, Any]]:
        """
        åˆ›å»ºç¿»è¯‘é…ç½®
        
        Returns:
            (translate_config,): ç¿»è¯‘é…ç½®å­—å…¸
        """
        config = {
            "translator_type": ç¿»è¯‘å™¨ç±»å‹,
            "target_language": ç›®æ ‡è¯­è¨€,
            "thread_num": çº¿ç¨‹æ•°,
            "batch_num": æ‰¹å¤„ç†æ•°é‡,
            "is_reflect": åæ€ç¿»è¯‘,
            "llm_config": LLMé…ç½®,
        }
        
        return (config,)


NODE_CLASS_MAPPINGS = {
    "TranscribeConfigNode": TranscribeConfigNode,
    "LLMConfigNode": LLMConfigNode,
    "TranslateConfigNode": TranslateConfigNode,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "TranscribeConfigNode": "è½¬å½•é…ç½®",
    "LLMConfigNode": "LLM é…ç½®",
    "TranslateConfigNode": "ç¿»è¯‘é…ç½®",
}

